{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip install --upgrade git+https://github.com/huggingface/transformers.git accelerate datasets[audio]\n",
    "# %pip install ipywidgets\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "#\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "model_id ='openai/whisper-small'\n",
    "model = WhisperModel(\"model\", local_files_only=True,device=\"cuda\", compute_type=\"float16\")\n",
    "# model.to(device)\n",
    "\n",
    "# processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     \"automatic-speech-recognition\",\n",
    "#     model=model,\n",
    "#     tokenizer=processor.tokenizer,\n",
    "#     feature_extractor=processor.feature_extractor,\n",
    "#     max_new_tokens=128,\n",
    "#     chunk_length_s=30,\n",
    "#     batch_size=16,\n",
    "#     return_timestamps=True,\n",
    "#     torch_dtype=torch_dtype,\n",
    "#     device=device,\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample = dataset[0][\"audio\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
       "       0.0005188 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 132 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "segments, info = model.transcribe(sample['array'], beam_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'en' with probability 0.999023\n",
      "[0.00s -> 6.56s]  Mr. Quilter is the apostle of the Middle Classes, and we are glad to welcome his Gospel.\n",
      "[6.56s -> 11.28s]  Nor is Mr. Quilter's manner less interesting than his matter.\n",
      "[11.28s -> 16.84s]  He tells us that at this festive season of the year, with Christmas and roast beef looming\n",
      "[16.84s -> 23.76s]  before us, symbolies drawn from eating and its results occur most readily to the mind.\n",
      "[23.76s -> 29.56s]  He has grave doubts whether Sir Frederick Layton's work is really Greek after all, and can\n",
      "[29.56s -> 33.00s]  discover in it but little of rocky Ithaca.\n",
      "[33.00s -> 40.28s]  Linnell's pictures are a sort of up-guards-and-atom paintings, and Mason's exquisite idylls\n",
      "[40.28s -> 44.72s]  are as national as a jingle poem.\n",
      "[44.72s -> 50.32s]  Mr. Birkitt Foster's landscapes smile at one much in the same way that Mr. Karker used\n",
      "[50.32s -> 57.84s]  to flash his teeth, and Mr. John Collier gives his sitter a cheerful slap on the back, before\n",
      "[57.84s -> 62.00s]  he says, like a shampooer in a Turkish bath, next man.\n"
     ]
    }
   ],
   "source": [
    "segments, info = model.transcribe(sample['array'], beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
